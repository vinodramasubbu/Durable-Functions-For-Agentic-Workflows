# This function is not intended to be invoked directly. Instead it will be
# triggered by an orchestrator function.
# Before running this sample, please:
# - create a Durable orchestration function
# - create a Durable HTTP starter function
# - add azure-functions-durable to requirements.txt
# - run pip install -r requirements.txt

import os
import logging
import psycopg2
import pandas as pd
import json
from psycopg2.extras import RealDictCursor
import decimal
import datetime
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from datetime import datetime, timedelta
from langchain_experimental.utilities import PythonREPL

BING_SUBSCRIPTION_KEY = os.environ["BING_SUBSCRIPTION_KEY"] 
BING_SEARCH_URL = os.environ["BING_SEARCH_URL"] 
AZURE_OPENAI_KEY = os.environ["AZURE_OPENAI_KEY"] 
AZURE_OPENAI_ENDPOINT = os.environ["AZURE_OPENAI_ENDPOINT"] 
AZURE_OPENAI_DEPLOYMENT = os.environ["AZURE_OPENAI_DEPLOYMENT"] 
AZURE_OPENAI_VERSION = os.environ["AZURE_OPENAI_VERSION"] 
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT = os.environ["AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT"] 

# Fetch data from the policy administration system
PGHOST = os.environ["PGHOST"]
PGUSER = os.environ["PGUSER"]
PGPORT =os.environ["PGPORT"]
PGDATABASE = os.environ["PGDATABASE"]
PGPASSWORD = os.environ["PGPASSWORD"]
connectionString = f"postgresql://{PGUSER}:{PGPASSWORD}@{PGHOST}:{PGPORT}/{PGDATABASE}"

repl = PythonREPL()

def main(name: str) -> str:

    code_gen_prompt = ChatPromptTemplate.from_messages(
    [
        (
            "system",
            """
            You need to write a Python script that queries a PostgreSQL database for wholesale_casualty_insurance_policies data and convert the output to a ditcionary and print it.

            Use the variable connectionString to connect to the PostgreSQL database.
            Exclude the line of code that defines the connectionString variable.

            table name: wholesale_casualty_insurance_policies
            Columns:
            policy_id,company_name, policy_type, coverage_amount, premium, deductible, policy_start_date, policy_end_date, number_of_employees, industry, location, number_of_claims

            Here is the user question and the connectionString to use in the code:
            """,
        ),
        ("placeholder", "{messages}"),
        ("placeholder", "{connectionString}"),
    ]
    )

    llm = AzureChatOpenAI(
            api_version=os.environ["AZURE_OPENAI_VERSION"],
            api_key=os.environ["AZURE_OPENAI_KEY"],
            azure_deployment=os.environ["AZURE_OPENAI_DEPLOYMENT"],
            azure_endpoint=os.environ["AZURE_OPENAI_ENDPOINT"],
            temperature = 0.1
        )
    
    json_schema = {
            "title": "llm_code",
            "description": "generate code.",
            "type": "object",
            "properties": {
                "prefix": {
                    "type": "string",
                    "description": "Description of the code",
                },
                "imports": {
                    "type": "string",
                    "description": "Code block import statements"
                },
                "code": {
                    "type": "string",
                    "description": "Code block not including import statements"
                },
            },
            "required": ["prefix", "imports", "code"],
        }
    
    question = name
    code_gen_chain = code_gen_prompt | llm.with_structured_output(json_schema)

    code_result = code_gen_chain.invoke({"messages": [("user", question)]})

    code_to_execute = "connectionString="+f'"{connectionString}"'+ "\n" +(code_result['imports']) + "\n" + (code_result['code'])

    print(code_to_execute)

    repl_result = repl.run(code_to_execute)

    # Convert repl_result to JSON
    repl_result_json = json.dumps(repl_result, indent=2)

    print("################################################")
    print("LLM Generated code:")
    print("################################################")
    print(code_to_execute)

    print("################################################")
    print("LLM Generated code to execution results:")
    print("################################################")

    print(type(repl_result_json))

    return f"{repl_result_json}"
